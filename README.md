# VulnBuilderAI: Ferramenta Multiplataforma para Constru√ß√£o de Datasets de Vulnerabilidades com Categoriza√ß√£o por IA

[![Licen√ßa](https://img.shields.io/badge/License-GNU%20GPL-blue)](https://opensource.org/licenses/GNU)

**Resumo do Artigo:**

_Este projeto apresenta o VulnBuilderAI, uma ferramenta para construir datasets de vulnerabilidades de software. A ferramenta coleta dados de m√∫ltiplas fontes, normaliza, extrai informa√ß√µes relevantes usando PLN (incluindo LLMs) e categoriza as vulnerabilidades. O objetivo √© gerar datasets de alta qualidade para pesquisa e pr√°tica em seguran√ßa de software._

---

## Estrutura do README.md

Este README.md est√° organizado nas seguintes se√ß√µes:

1.  **T√≠tulo e Resumo:** T√≠tulo do projeto e um resumo conciso (c√≥pia do resumo do artigo).
2.  **Estrutura do README.md:** Estrutura do presente README.md.
3.  **Selos:** Estrutura com os Selos Considerados
3.  **Informa√ß√µes b√°sicas:** Esta se√ß√£o deve apresentar informa√ß√µes b√°sicas de todos os componentes necess√°rios para a execu√ß√£o e replica√ß√£o dos experimentos. Descrevendo todo o ambiente de execu√ß√£o, com requisitos de hardware e software.
4.  **Dep√™ndencias:** Informa√ß√µes relacionadas a benchmarks utilizados e depend√™ncias para a execu√ß√£o s√£o descritas nesta se√ß√£o. 
Buscou-se deixar o mais claro poss√≠vel, apresentando informa√ß√µes como vers√µes de depend√™ncias e processos para acessar recursos de terceiros caso necess√°rio.
5.  **Preocupa√ß√µes com seguran√ßa:** Lista das preocupa√ß√µes com a seguran√ßa.
6.  **Instala√ß√£o:** O processo de baixar e instalar a aplica√ß√£o deve ser descrito nesta se√ß√£o.
7.  **Teste m√≠nimo:** Explica√ß√£o dos argumentos de linha de comando e exemplos de uso local e por API.
8.  **Experimentos:** Descreve um passo a passo para a execu√ß√£o e obten√ß√£o dos resultados do artigo. Permitindo que os revisores consigam alcan√ßar as reivindica√ß√µes apresentadas no artigo. 
9. **Licen√ßa:** Informa√ß√µes sobre a licen√ßa do projeto.
10. **Revis√£o Sist√™mica da Ferramenta:** Uma revis√£o mais aprofundada da Ferramenta.
--- 

## Selos Considerados
Os selos considerados no processo de avalia√ß√£o s√£o: **Dispon√≠veis**, **Funcionais**, **Sustent√°veis** e **Experimentos Reprodut√≠veis**.

# Informa√ß√µes B√°sicas

Esta se√ß√£o apresenta todos os componentes essenciais que foram necess√°rios para a execu√ß√£o e replica√ß√£o dos experimentos, incluindo detalhes sobre o ambiente de execu√ß√£o e os requisitos de hardware e software.


- **Ambiente de Execu√ß√£o**
  - Os experimentos para executar os estudos de casos usando a API do Gemini e DeepSeek foram realizados em um computador com processador Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz   2.81 GHz (4 n√∫cleos) e 16GB de mem√≥ria RAM, rodando o sistema opera-cional Windows 10 Home. 
  - **Sistemas Operacionais Suportados:**
    - Windows 10 ou superior

  - Para rodar o estudo de caso rodando a configura√ß√£o local do Llama3 (DeepHermes-3-Llama-3-8B-Preview3) foram usados uma m√°quina virtual (VMs) na Google Cloud com a seguinte configura√ß√£o: e2-custom-12-40960 (12 vCPUs, 40 GB de mem√≥ria), Ubuntu-2004-focal-v20250213.
  - **Sistemas Operacionais Suportados:**
    - Ubuntu 20.04 LTS (ou equivalente com suporte a Python 3.10)

- **Arquitetura:** x86_64.
- **Linguagem de Programa√ß√£o:** Python 3.10.

**Requisitos de Hardware API**

- **CPU:** Processador com no m√≠nimo 4 n√∫cleos (recomendado Intel i5 ou equivalente).
- **Mem√≥ria RAM:** M√≠nimo de 8 GB (16 GB recomendados para grandes volumes de dados).
- **Espa√ßo em Disco:** Pelo menos 10 GB livres para armazenamento de dados e depend√™ncias.
- **GPU (opcional):** GPU com suporte a CUDA (recomendado para uso com `torch` e treinamentos de modelos).
- **Ambiente do Estudo de Caso:**
  - **Processador:** Intel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz 2.81GHz (4 n√∫cleos).
  - **Mem√≥ria RAM:** 16 GB.
  - **Sistema Operacional:** Windows 10 Home.

**Requisitos de Hardware Local Google Cloud**

- **CPU:** Processador com no m√≠nimo 12 vCPUs n√∫cleos.
- **Mem√≥ria RAM:** M√≠nimo de 8 GB (16 GB recomendados para grandes volumes de dados.
- **Espa√ßo em Disco:** Pelo menos 10 GB livres para armazenamento de dados e depend√™ncias.
- **GPU (opcional):** N√£o utilizada, execu√ß√£o por CPU.
- **Ambiente do Estudo de Caso:**
  - **Processador:** e2-custom-12-40960).
  - **Mem√≥ria RAM:** 40 GB.
  - **Sistema Operacional:** Ubuntu 20.04 LTS, arquiteturas x86_64.

**Requisitos de Software**

- **Python 3.10:** Certifique-se de que est√° instalado no sistema.
- **Gerenciador de Pacotes:** `pip` ou equivalente para instala√ß√£o das depend√™ncias.
- **Ferramentas Adicionais:**
  - Git para clonagem do reposit√≥rio.
  - Ambiente virtual (opcional, mas recomendado) para isolamento do projeto.
---

Esta se√ß√£o foi estruturada para fornecer clareza total sobre todas as depend√™ncias envolvidas, garantindo que os experimentos sejam reprodut√≠veis e acess√≠veis. Se precisar de mais informa√ß√µes ou ajustes, posso complementar! üòä


---
## Depend√™ncias de Software

Abaixo est√£o listadas as principais bibliotecas e ferramentas necess√°rias, bem como suas vers√µes:

- `requests`: vers√£o 2.31.0
- `google-generativeai`: vers√£o 0.1.3
- `openai`: vers√£o 0.27.2
- `transformers`: vers√£o 4.27.4
- `psutil`: vers√£o 5.9.4
- `huggingface_hub`: vers√£o 0.13.3
- `torch`: vers√£o 2.0.0

## Preocupa√ß√µes com seguran√ßa

Caso a execu√ß√£o do artefato ofere√ßa qualquer tipo de risco, esta se√ß√£o detalha os potenciais perigos e descreve os processos necess√°rios para garantir a seguran√ßa dos avaliadores.

**Riscos Potenciais**

1. **Uso de Recursos Externos:**
   - Depend√™ncias externas ou APIs podem expor chaves de autentica√ß√£o ou dados sens√≠veis, caso n√£o sejam configuradas adequadamente.
   - √â importante assegurar que qualquer dado enviado a terceiros esteja em conformidade com pol√≠ticas de privacidade e seguran√ßa.

2. **Execu√ß√£o de C√≥digo:**
   - O uso de scripts automatizados, especialmente aqueles com permiss√µes elevadas, pode representar riscos se forem configurados incorretamente.
   - Erros no c√≥digo podem levar ao uso indevido de recursos, como consumo excessivo de CPU/GPU ou perda de dados.

3. **Manipula√ß√£o de Dados Brutos:**
   - Dados n√£o sanitizados podem conter informa√ß√µes prejudiciais ou maliciosas, representando um risco para o sistema onde s√£o processados.

**Medidas de Seguran√ßa**

1. **Gerenciamento de Chaves de API:**
   - Assegura que as chaves de API sejam armazenadas em vari√°veis de ambiente e nunca diretamente no c√≥digo.
   - Exemplo de configura√ß√£o:
     ```bash
     export API_KEY="SUA_CHAVE_SEGURA_AQUI"
     ```

2. **Execu√ß√£o em Ambientes Isolados:**
   - Utiliza ambientes virtuais ou cont√™ineres (e.g., Docker) para isolar a execu√ß√£o do artefato.
   - Recomenda√ß√£o para criar um cont√™iner:
     ```bash
     docker build -t vuln-builder-ai .
     docker run -p 8000:8000 vuln-builder-ai
     ```

3. **Documenta√ß√£o de Restri√ß√µes:**
   - Informa aos revisores quaisquer restri√ß√µes ou pr√©-requisitos para garantir a execu√ß√£o segura do artefato.

**Responsabilidade**

- Todos os scripts fornecidos foram projetados para minimizar riscos √† seguran√ßa. No entanto, √© responsabilidade do usu√°rio garantir que o ambiente de execu√ß√£o seja seguro e que as pr√°ticas recomendadas descritas acima sejam seguidas.

## Instala√ß√£o e Execu√ß√£o
1. Clone o reposit√≥rio:
   ```bash
   git clone https://github.com/seuprojeto/seurepositorio.git
   cd seurepositorio

**Pr√©-requisitos**

- Python 3.8 ou superior.
- Chaves de API para os seguintes servi√ßos (opcional, dependendo dos m√≥dulos e LLMs que voc√™ for usar):
  - **Vulners:** Obtenha uma chave em [https://vulners.com/](https://vulners.com/)
  - **Google Gemini:** Obtenha uma chave em [https://ai.google.dev/](https://ai.google.dev/)
  - **OpenAI ChatGPT:** Obtenha uma chave em [https://platform.openai.com/](https://platform.openai.com/)
  - **Llama (Meta):** Obtenha uma chave em [https://llama-api.com/](https://llama-api.com/)

**Instala√ß√£o**

1.  **Clone o reposit√≥rio:**

    ```bash
    git clone https://github.com/douglasfideles/VulnBuilderAI.git
    cd VulnBuilderAI
    ```

2.  **Crie um ambiente virtual (recomendado):**

    ```bash
    python3 -m venv .venv
    source .venv/bin/activate  # Linux/macOS
    .venv\Scripts\activate  # Windows
    ```

3.  **Instale as depend√™ncias:**

    ```bash
    pip install -r requirements.txt
    ```

    Caso tenha problemas, instale individualmente:

    ```bash
      pip install google-generativeai
      pip install openai
      pip install requests
    ```

**Configura√ß√£o**

Voc√™ pode configurar o VulnBuilderAI usando _vari√°veis de ambiente_ ou _argumentos de linha de comando_. A ordem de prioridade √©: argumentos de linha de comando > vari√°veis de ambiente.

1.  **Arquivo de configura√ß√£o (opcional):**
    _N√£o implementado no c√≥digo fornecido._ Se voc√™ quisesse adicionar um arquivo de configura√ß√£o (e.g., `config.ini` ou `config.yaml`), precisaria modificar o c√≥digo (`main.py`) para ler as configura√ß√µes desse arquivo.

### Teste m√≠nimo

1.  **Usando todas as IAs, ambas as fontes e m√∫ltiplos termos de busca:**

    ```bash
    python src/main.py --provider 'gemini' --data-source both --search-params "OpenDDS" "RTI Connext DDS" --export-format csv --output-file vulnerabilidades.csv
    ```

    - `--provider 'gemini' `: Usa provider 'gemini' para definir Gemini como classificador.
    - `--data-source both`: Usa NVD e Vulners.
    - `--search-params`: Busca por vulnerabilidades relacionadas a "OpenDDS" _e_ "RTI Connext DDS".
    - `--export-format csv`: Exporta para csv, tamb√©m poss√≠vel json
    - O resultado √© salvo em `vulnerabilidades.csv`.

2.  **Sem IA, usando apenas o NVD:**

    ```bash
    python src/main.py ==provider none --data-source nvd --search-params "OpenDDS" --export-format csv --output-file vulnerabilidades_nvd.csv
    ```

    - `--provider none`: _N√£o_ usa IA para categoriza√ß√£o. Os campos de categoria (CWE, etc.) ficar√£o como "UNKNOWN".
    - `--data-source nvd`: Usa _apenas_ o NVD.
    - N√£o precisa de chaves de API de LLMs.

3.  **Usando Gemini, Vulners e um arquivo com termos de busca:**

    Crie um arquivo `search_terms.txt` com o seguinte conte√∫do (um termo por linha):

    ```
    OpenDDS
    RTI Connext DDS
    Eclipse Cyclone DDS
    ```

    Execute:

    ```bash
    python src/main.py --provider 'gemini' --data-source 'vulners' --search-file search_terms.txt --output-file vulnerabilidades_gemini.csv
    ```

    - `--provider gemini`
    - `--search-file`: Usa o arquivo `search_terms.txt`.

## Experimentos

Esta se√ß√£o descreve como reproduzir os experimentos apresentados no artigo.

**Reivindica√ß√£o #1 (Exemplo: Coleta e Categoriza√ß√£o de Vulnerabilidades em Browsers local)**

- **Objetivo:** Demonstrar a capacidade da ferramenta de coletar dados de vulnerabilidades relacionadas a DDS, pr√©-process√°-los, extrair informa√ß√µes e categoriz√°-los usando LLMs.

- **Passos:**

  1. **Configura√ß√£o:**

     - Certifique-se de que as chaves de API (Vulners, Gemini, ChatGPT, Llama) est√£o configuradas corretamente (vari√°veis de ambiente ou argumentos de linha de comando).
     - Crie um arquivo (ex: `search_params_Browsers.txt`) contendo os termos de busca relacionados a DDS (ou utilize o arquivo que est√° no diret√≥rio search_params/search_params_DDS.txt):

       ```       
      Google Chrome Browser
      Microsoft Edge Browser
      Mozilla Firefox Browser
      Apple Safari Browser
      Opera Browser
       ```

  2. **Execu√ß√£o:** Execute o seguinte comando (adaptando os nomes dos arquivos e as chaves de API, se necess√°rio):

     ```bash
       python3 src/main.py --provider "llama3"  --data-source 'nvd'  --search-file search-params_BROWSERS.txt --export-format csv --output-file vulners4.csv


     ```

     - `--provider llama3`: Usa todos os LLMs (Llama 3).
     - `--data-source nvd`: Usa NVD .
     - `--search-file search_params_Browser.txt`: Usa o arquivo com os termos de busca.
     - `--output-file vulners4.csv`: Salva os resultados em `vulners4.csv`.

  3. **Verifica√ß√£o:**
     - Verifique se o arquivo `llama3_dataset/vulners4.csv` foi criado.
     - Abra o arquivo e verifique se ele cont√©m os dados esperados:
       - Colunas com os campos b√°sicos (ID, t√≠tulo, descri√ß√£o, etc.).
       - Colunas adicionais com as categorias extra√≠das pelos LLMs (CWE, explica√ß√£o, fornecedor, causa, impacto).
       - Os valores devem corresponder, aproximadamente, aos resultados apresentados nas tabelas e gr√°ficos do artigo (pequenas varia√ß√µes s√£o esperadas devido √† natureza estoc√°stica dos LLMs).

**Reivindica√ß√£o #2 (Estudo de Caso MQTT local):**

- **Objetivo:** Demonstrar a capacidade da ferramenta de coletar dados de vulnerabilidades relacionadas ao protocolo MQTT, pr√©-process√°-los, extrair informa√ß√µes relevantes e categoriz√°-los usando LLMs.

- **Passos:**

  1. **Configura√ß√£o:**

     - Certifique-se de que as chaves de API (Vulners, Gemini, ChatGPT, Llama) est√£o configuradas corretamente (vari√°veis de ambiente ou argumentos de linha de comando).
     - Crie um arquivo (ex: `search_params_MQTT.txt`) contendo os termos de busca relacionados a MQTT:

       ```
       Eclipse Mosquitto
       EMQX
       VerneMQ
       RabbitMQ
       HiveMQ
       ```

  2. **Execu√ß√£o:** Execute o seguinte comando (adaptando os nomes dos arquivos e as chaves de API, se necess√°rio):

     ```bash
      python3 src/main.py --provider llama3 --data-source 'vulners' --search-file serrch.txt --export-format csv --output-file MQTT_vulnerabilities_categorized-LOCAL-LLM-VULNERS.csv

     ```

     - `--provider llama3`: Usa o LLMs (Llama).
     - `--data-source vulners`: Usa Vulners.
     - `--search-file search_params_MQTT.txt`: Usa o arquivo com os termos de busca.
     - `--output-file MQTT_vulnerabilities_categorized-LOCAL-LLM-VULNERS.csv`: Salva os resultados em `llama3_dataset/MQTT_vulnerabilities_categorized-LOCAL-LLM-VULNERS.csv`.

  3. **Verifica√ß√£o:**
     - Verifique se o arquivo `llama3_dataset/MQTT_vulnerabilities_categorized-LOCAL-LLM-VULNERS.csv` foi criado.
     - Abra o arquivo e verifique se ele cont√©m os dados esperados:
       - Colunas com os campos b√°sicos (ID, t√≠tulo, descri√ß√£o, etc.).
       - Colunas adicionais com as categorias extra√≠das pelos LLMs (CWE, explica√ß√£o, fornecedor, causa, impacto).
       - Os valores devem corresponder, aproximadamente, aos resultados apresentados nas tabelas e gr√°ficos do artigo (pequenas varia√ß√µes s√£o esperadas devido √† natureza estoc√°stica dos LLMs).

**Reivindica√ß√£o #3 (Estudo de Caso MQTT Api):**

- **Objetivo:** Demonstrar a capacidade da ferramenta de coletar dados de vulnerabilidades relacionadas ao protocolo MQTT, pr√©-process√°-los, extrair informa√ß√µes relevantes e categoriz√°-los usando LLMs.

- **Passos:**

  1. **Configura√ß√£o:**

     - Certifique-se de que as chaves de API (Vulners, Gemini, ChatGPT, Llama) est√£o configuradas corretamente (vari√°veis de ambiente ou argumentos de linha de comando).
     - Crie um arquivo (ex: `search_params_MQTT.txt`) contendo os termos de busca relacionados a MQTT:

       ```
       Eclipse Mosquitto
       EMQX
       VerneMQ
       RabbitMQ
       HiveMQ
       ```

  2. **Execu√ß√£o:** Execute o seguinte comando (adaptando os nomes dos arquivos e as chaves de API, se necess√°rio):

     ```bash
      python3 src/main.py --provider llama3 --data-source 'vulners' --search-file serrch.txt --export-format csv --output-file MQTT_vulnerabilities_categorized-LOCAL-LLM-VULNERS.csv

     ```

     - `--provider llama3`: Usa o LLMs (Llama).
     - `--data-source vulners`: Usa Vulners.
     - `--search-file search_params_MQTT.txt`: Usa o arquivo com os termos de busca.
     - `--output-file MQTT_vulnerabilities_categorized-LOCAL-LLM-VULNERS.csv`: Salva os resultados em `llama3_dataset/MQTT_vulnerabilities_categorized-LOCAL-LLM-VULNERS.csv`.

  3. **Verifica√ß√£o:**
     - Verifique se o arquivo `llama3_dataset/MQTT_vulnerabilities_categorized-LOCAL-LLM-VULNERS.csv` foi criado.
     - Abra o arquivo e verifique se ele cont√©m os dados esperados:
       - Colunas com os campos b√°sicos (ID, t√≠tulo, descri√ß√£o, etc.).
       - Colunas adicionais com as categorias extra√≠das pelos LLMs (CWE, explica√ß√£o, fornecedor, causa, impacto).
       - Os valores devem corresponder, aproximadamente, aos resultados apresentados nas tabelas e gr√°ficos do artigo (pequenas varia√ß√µes s√£o esperadas devido √† natureza estoc√°stica dos LLMs).


**Reivindica√ß√£o #4 (Estudo de Caso Navegadores Web por API):**

- **Objetivo:** Demonstrar a capacidade da ferramenta de coletar dados de vulnerabilidades relacionadas a navegadores web (browsers), pr√©-process√°-los, extrair informa√ß√µes relevantes e categoriz√°-los usando LLMs.

- **Passos:**

  1. **Configura√ß√£o:**

     - Certifique-se de que as chaves de API (Vulners, Gemini, ChatGPT, Llama) est√£o configuradas corretamente.
     - Crie um arquivo (ex: `search_params_BROWSERS.txt`) contendo os termos de busca relacionados a navegadores:

       ```
       Google Chrome Browser
       Microsoft Edge Browser
       Mozilla Firefox Browser
       Apple Safari Browser
       Opera Browser
       ```

  2. **Execu√ß√£o:**

     ```bash
     python src/main.py --provider 'gemini' --data-source 'nvd' --search-file search_files/search-params_BROWSERS.txt --export-format csv --output-file BROWSERS_vulnerabilities_categorized-GEMINI.csv

     ```

     - `--provider combined`: Usa todos os LLMs.
     - `--data-source nvd`: Usa NVD.
     - `--search-file search_files/search_params_browsers.txt`: Usa o arquivo com os termos de busca.
     - `--output-file BROWSERS_vulnerabilities_categorized-GEMINI.csv`: Salva os resultados em `gemini_dataset/BROWSERS_vulnerabilities_categorized-GEMINI.csv`.

     
  3. **Verifica√ß√£o:**
     - Verifique se o arquivo `dataset/browsers_vulnerabilities.csv` foi criado.
     - Abra o arquivo e verifique se ele cont√©m os dados esperados:
       - Colunas com os campos b√°sicos (ID, t√≠tulo, descri√ß√£o, etc.).
       - Colunas adicionais com as categorias extra√≠das pelos LLMs (CWE, explica√ß√£o, fornecedor, causa, impacto).
       - Os valores devem corresponder, aproximadamente, aos resultados apresentados nas tabelas e gr√°ficos do artigo (pequenas varia√ß√µes s√£o esperadas devido √† natureza estoc√°stica dos LLMs).



**Reivindica√ß√£o #5 (Estudo de Caso UAV por API):**

- **Objetivo:** Demonstrar a capacidade da ferramenta de coletar dados de vulnerabilidades relacionadas a navegadores web (browsers), pr√©-process√°-los, extrair informa√ß√µes relevantes e categoriz√°-los usando LLMs.

- **Passos:**

  1. **Configura√ß√£o:**

     - Certifique-se de que as chaves de API (Vulners, Gemini, ChatGPT, Llama) est√£o configuradas corretamente.
     - Crie um arquivo (ex: `search_params_UAV.txt`) contendo os termos de busca relacionados a navegadores:

       ```
        AODV
        DSR
        OLSR

       ```

  2. **Execu√ß√£o:**

     ```bash
     python src/main.py --provider 'gemini' --data-source 'nvd' --search-file search_files/search-params_UAV.txt --export-format csv --output-file UAV_vulnerabilities_categorized-GEMINI.csv

     ```

     - `--provider gemini`: Usa todos os LLMs.
     - `--data-source nvd`: Usa NVD.
     - `--search-file search_files/search_params_UAV.txt`: Usa o arquivo com os termos de busca.
     - `--output-file UAV_vulnerabilities_categorized-GEMINI.csv`: Salva os resultados em `gemini_dataset/UAV_vulnerabilities_categorized-GEMINI.csv`.

     
  3. **Verifica√ß√£o:**
     - Verifique se o arquivo `gemini_dataset UAV_vulnerabilities_categorized-GEMINI.csv` foi criado.
     - Abra o arquivo e verifique se ele cont√©m os dados esperados:
       - Colunas com os campos b√°sicos (ID, t√≠tulo, descri√ß√£o, etc.).
       - Colunas adicionais com as categorias extra√≠das pelos LLMs (CWE, explica√ß√£o, fornecedor, causa, impacto).
       - Os valores devem corresponder, aproximadamente, aos resultados apresentados nas tabelas e gr√°ficos do artigo (pequenas varia√ß√µes s√£o esperadas devido √† natureza estoc√°stica dos LLMs).

## Licen√ßa

- Este projeto est√° licenciado sob os termos da [MIT License](https://opensource.org/licenses/MIT). Isso significa que voc√™ pode usar, modificar e distribuir este software conforme os termos da licen√ßa, desde que a atribui√ß√£o original seja mantida.

- Consulte o arquivo [LICENSE](LICENSE) para obter mais detalhes.

## Revis√£o sist√™mica

**Observa√ß√µes Gerais (para todos os estudos de caso):**

- **Reprodutibilidade:** Os resultados _exatos_ podem variar um pouco devido a:
  - **Atualiza√ß√µes nas bases de dados:** O NVD e o Vulners s√£o _constantemente atualizados_. Novas vulnerabilidades podem ser adicionadas, e as informa√ß√µes sobre vulnerabilidades existentes podem ser modificadas.
  - **Estocasticidade dos LLMs:** Os LLMs (Gemini, ChatGPT, Llama) _n√£o s√£o completamente determin√≠sticos_. Pequenas varia√ß√µes nas respostas s√£o esperadas, mesmo com o mesmo prompt e os mesmos dados de entrada. O sistema de vota√ß√£o ponderada ajuda a mitigar isso, mas n√£o elimina _completamente_ a variabilidade.
- **Tempo de Execu√ß√£o:** A coleta de dados, especialmente do Vulners, e a categoriza√ß√£o com os LLMs _podem levar um tempo consider√°vel_ (dependendo do n√∫mero de termos de busca, da quantidade de vulnerabilidades encontradas e da velocidade da sua conex√£o com a internet e das APIs). Seja paciente.
- **Erros/Exce√ß√µes:**
- O c√≥digo fornecido tem _algum_ tratamento de erros (e.g., `try...except` para chamadas de API), mas _n√£o √© exaustivo_. √â _poss√≠vel_ que ocorram erros durante a execu√ß√£o (e.g., problemas de conex√£o, limites de taxa de API, etc.).
- Se ocorrerem erros, _leia atentamente as mensagens de erro_. Elas podem fornecer pistas sobre o problema.
- Verifique se as _chaves de API_ est√£o corretas e se voc√™ _n√£o atingiu os limites de uso_ das APIs.
- Verifique sua conex√£o com a internet\_.
- **Dados de Sa√≠da:**
  - Os arquivos CSV gerados ter√£o as colunas especificadas no c√≥digo (`id`, `title`, `description`, `vendor`, `cwe_category`, etc.).
  - Os valores para `cwe_category`, `explanation`, `vendor`, `cause` e `impact` ser√£o preenchidos pelos LLMs (ou "UNKNOWN" se a categoriza√ß√£o falhar).
  - Os valores para `published`, `cvss_score`, `severity` e `source` vir√£o das fontes de dados (NVD ou Vulners).

## Docker

Voc√™ tamb√©m pode executar o script usando Docker.

### Dockerfile

```dockerfile
# Use uma imagem oficial do Python como imagem base
FROM python:3.10-slim

# Defina o diret√≥rio de trabalho no cont√™iner
WORKDIR /app

# Copie o conte√∫do do diret√≥rio atual para o cont√™iner em /app
COPY . /app

# Instale os pacotes necess√°rios especificados em requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Defina a vari√°vel de ambiente
ENV NAME DDSBuilder

# Execute main.py quando o cont√™iner for iniciado
CMD ["python", "src/main.py"]
```

### Construir e Executar o Cont√™iner Docker

1.  **Construir a imagem:**

    ```bash
    docker build -t vbuilder .
    ```

2.  **Executar o container usando IA para categoriza√ß√£o:**

    ```bash
    docker run vbuilder python src/main.py --provider provider --data-source both --export-format csv --output-file vulnerabilidades.csv --search-params "OpenDDS" "RTI Connext DDS"
    ```

3.  **Executar o container sem usar IA para categoriza√ß√£o:**

    ```bash
    docker run --provider none --data-source nvd --export-format csv --output-file vulnerabilidades.csv --search-params "OpenDDS"
    ```

## Estrutura do C√≥digo

O c√≥digo-fonte est√° organizado da seguinte forma:

- `categorization/`: Cont√©m os m√≥dulos relacionados √† categoriza√ß√£o de vulnerabilidades com IA.
  - `categorizer.py`: Implementa a classe `Categorizer`, respons√°vel por interagir com as APIs dos LLMs e combinar os resultados.
  - `__init__.py`
  - `voting.py`: Implementa um sistema de vota√ß√£o.
- `data_sources/`: Cont√©m os m√≥dulos para extrair dados de diferentes fontes.
  - `nvd_extractor.py`: Fun√ß√µes para acessar a API do NVD.
  - `vulners_extractor.py`: Fun√ß√µes para acessar a API do Vulners.
  - `github_extractor.py`: (Atualmente n√£o utilizado)
  - `__init__.py`
- `output/`: Cont√©m os m√≥dulos para exportar os dados processados.
  - `csv_exporter.py`: Fun√ß√µes para exportar dados para CSV.
  - `__init__.py`
  - `json_exporter.py`: Fun√ß√µes para exportar dados para JSON.
- `processing/`: Cont√©m m√≥dulos para processamento e normaliza√ß√£o dos dados.
  - `filter.py`: Fun√ß√µes para filtrar as vulnerabilidades.
  - `normalizer.py`: Fun√ß√µes para normalizar os dados de diferentes fontes.
  - `load_data_source.py`:Carrega as fontes de dados.
  - `data_preprocessor.py`: Orquestra o pr√©-processamento dos dados. -`__init__.py`
- `src/`: Cont√©m o script principal.
  - `main.py`: Ponto de entrada principal do programa.
- `requirements.txt`: Lista as depend√™ncias do projeto.
- `README.md`: Este arquivo.
- search-params-\*.txt: Arquivos contendo termos para pesquisa.
- config.yaml: Arquivo de configura√ß√£o.

## Extensibilidade

O VulnBuilderAI foi projetado para ser extens√≠vel, permitindo a adi√ß√£o de novas fontes de dados, normalizadores e formatos de sa√≠da de forma simples e organizada. A arquitetura modular da ferramenta facilita a integra√ß√£o de novos componentes sem a necessidade de modificar o c√≥digo principal. A seguir, descrevemos como adicionar novas fontes de dados e novos formatos de sa√≠da.

### Adicionando Novas Fontes de Dados

Para adicionar uma nova fonte de dados, siga os seguintes passos:

1.  **Crie um Novo M√≥dulo Extractor:**

    - Dentro do diret√≥rio `data_sources/`, crie um novo arquivo Python com um nome descritivo para a nova fonte de dados, seguindo o padr√£o `nova_fonte_extractor.py`. Por exemplo, se voc√™ deseja adicionar uma fonte chamada "MySource", crie o arquivo `data_sources/mysource_extractor.py`.

2.  **Implemente a Classe Extractor:**

    - Dentro do novo arquivo (e.g., `mysource_extractor.py`), crie uma classe que herde da classe base `DataSourceBase` (definida em `data_sources/data_source.py`). Isso garante que a nova fonte de dados siga a interface esperada pela ferramenta.
    - Implemente o m√©todo `collect_data(self, search_params)`:

      - Este m√©todo √© respons√°vel por _coletar_ os dados da nova fonte.
      - Ele recebe uma lista de `search_params` (termos de busca).
      - Ele deve _retornar_ uma lista de _dicion√°rios_, onde cada dicion√°rio representa uma vulnerabilidade (ainda em um formato _bruto_, sem normaliza√ß√£o). _N√£o se preocupe com o formato dos dados neste ponto; a normaliza√ß√£o ser√° feita posteriormente._
      - Use a biblioteca `requests` para fazer as requisi√ß√µes HTTP, se necess√°rio. _Lembre-se de tratar erros e exce√ß√µes (conex√£o, rate limits, etc.) de forma adequada._
      - Se a nova fonte de dados tiver sua pr√≥pria API, use essa API. Se for uma p√°gina web, voc√™ pode usar bibliotecas como `BeautifulSoup` para fazer o parsing do HTML.
      - Exemplo:

        ```python
        # data_sources/mysource_extractor.py
        import requests
        from .data_source import DataSourceBase

        class MySourceExtractor(DataSourceBase):
            async def collect_data(self, search_params):
                vulnerabilities = []
                for param in search_params:
                    try:
                        # Exemplo de chamada de API (substitua pela l√≥gica real)
                        response = requests.get(f"https://api.mysource.com/vulnerabilities?q={param}")
                        response.raise_for_status()  # Lan√ßa exce√ß√£o se erro HTTP
                        data = response.json()
                        # Adapte a l√≥gica de extra√ß√£o para o formato da sua fonte
                        vulnerabilities.extend(data.get('vulnerabilities', [])) #Adiciona no fim
                    except requests.exceptions.RequestException as e:
                        print(f"Erro ao coletar dados da MySource para '{param}': {e}")
                return vulnerabilities

            def normalize_data(self, vulnerability):
              #Esta fun√ß√£o √© criada na etapa 5.
        ```

3.  **Atualize o Arquivo de Configura√ß√£o:**

    - Adicione a nova fonte de dados ao arquivo `config.yaml`:

    ```yaml
    data_sources:
      - nvd
      - vulners
      - mysource

      normalizers:
      - basic

      exporters:
      - csv
      - json
    ```

### Adicionando Novos Formatos de Sa√≠da

Para adicionar um novo formato de sa√≠da, siga os seguintes passos:

1.  **Crie um Novo M√≥dulo Exporter:**

    - Dentro do diret√≥rio output/, crie um novo arquivo Python com um nome descritivo para o novo formato de sa√≠da, seguindo o padr√£o novo_formato_exporter.py. Por exemplo, se voc√™ deseja adicionar um formato chamado "XML", crie o arquivo `output/xml_exporter.py`. Por exemplo, se voc√™ deseja adicionar um formato chamado "XML", crie o arquivo `output/xml_exporter.py`.

2.  **Implemente a Classe Exporter:**

    - Dentro do novo arquivo `(e.g., xml_exporter.py)`, crie uma classe que herde da classe base `DataExporterBase` (definida em `output/data_exporter.py`). Isso garante que o novo formato de sa√≠da siga a interface esperada pela ferramenta.
    - Implemente o m√©todo `export(self, data, filename)`:

      - Este m√©todo √© respons√°vel por exportar os dados no novo formato.
      - Ele recebe os dados a serem exportados e o nome do arquivo de sa√≠da.
      - Exemplo:

        ```python

        # output/xml_exporter.py

        import xml.etree.ElementTree as ET
        from .data_exporter import DataExporterBase

        class XmlExporter(DataExporterBase):
          def export(self, data, filename):
             root = ET.Element("Vulnerabilities")
            for item in data:
              vuln_elem = ET.SubElement(root, "Vulnerability")
               for key, value in item.items():
                child = ET.SubElement(vuln_elem, key)
                child.text = str(value)
            tree = ET.ElementTree(root)
          tree.write(filename, encoding='utf-8', xml_declaration=True
        ```

3.  **Atualize o Arquivo de Configura√ß√£o:**

    - Adicione o novo formato de sa√≠da ao arquivo `config.yaml`:

    ```yaml
    data_sources:
      - nvd
      - vulners
      - mysource

      normalizers:
      - basic

      exporters:
      - csv
      - json
      - xml
    ```

## Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa GNU - veja o arquivo [LICENSE](LICENSE) para mais detalhes.
